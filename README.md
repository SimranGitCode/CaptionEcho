 # CaptionEcho  

**CaptionEcho** is a web app that generates human-like captions for images, translates them into multiple languages, and converts them into audio. It combines state-of-the-art deep learning models from computer vision and natural language processing with text-to-speech technology to make visual content accessible and engaging.

  Key features of **CaptionEcho**:  
- **Image Captioning** – Automatically generates descriptive captions for any image.  
- **Sound Feature** – Captions can be spoken aloud using TTS.  
- **Translation** – Translate captions into multiple languages.  
- **Multi-language Speech** – Read translated captions aloud.  

This makes CaptionEcho a powerful tool for accessibility, language learning, and creative applications.

---

##   Features

- Upload any image and get a descriptive caption generated by **BLIP**.  
- Translate captions into Hindi, Tamil, Bengali, and more.  
- Convert captions and translations to MP3 audio using **gTTS**.  
- Simple and clean web interface built with **Flask**.  
- Optimized for speed using **PyTorch GPU acceleration** and **Flask-Compress**.

---

##   How It Works

1. Upload an image via the web interface.  
2. BLIP (Salesforce) generates a descriptive caption.  
3. The caption can be optionally translated into a selected language.  
4. Captions (original or translated) can be converted into audio for playback or download.  

---

##   Future Improvements

- Batch image uploads for faster processing.  
- Customizable voice settings for TTS (speed, pitch, accent).  
- Cloud deployment for scalable usage.  
- Enhanced UI with drag-and-drop and responsive design.  

---

##   Acknowledgements

- [Salesforce BLIP](https://huggingface.co/Salesforce/blip-image-captioning-base) for image captioning  
- Google Translate API for translation  
- gTTS for text-to-speech  
- PyTorch & Flask for model serving and web interface
